# MAYA Development Log - 2026-02-26

**Date:** Thursday, 26 February 2026
**Developer:** Srinivasan
**Session Goal:** Option 1 - Interactive chat loop with message history
**Status:** Completed

---

## Session Summary

Session 2 builds directly on the hello world graph from Session 1.
Added three things: farewell intent, message history (new LangGraph concept),
and an interactive REPL so MAYA can hold a real multi-turn conversation.

---

## What Was Built

### Files Changed
| File | Change |
|------|--------|
| `src/maya/models/state.py` | Added `message_history: Annotated[list[dict], operator.add]` |
| `src/maya/graph/hello_world_graph.py` | Added `farewell_response` node, 3-way routing, history in response nodes |
| `tests/test_hello_world.py` | Updated `invoke()` helper, added farewell + history tests |

### Files Created
| File | Purpose |
|------|---------|
| `chat_loop.py` | Interactive REPL - the main way to talk to MAYA now |
| `dev_log/2026-02-26.md` | This file |

---

## New LangGraph Concept: Annotated Reducer

The key new concept this session. In `state.py`:

```python
from typing import Annotated
import operator

class MayaState(TypedDict):
    message_history: Annotated[list[dict], operator.add]  # REDUCER
```

**Without Annotated (old behaviour):**
```
existing: ["item1", "item2"]
node returns: ["item3"]
result: ["item3"]          ← replaces entire list!
```

**With Annotated[list, operator.add]:**
```
existing: ["item1", "item2"]
node returns: ["item3"]
result: ["item1", "item2", "item3"]  ← appends!
```

This is how LangGraph accumulates message history as the graph processes each node.

---

## Updated Graph Flow

```
START
  ↓
[detect_language]       Hindi / English / Hinglish?
  ↓
[understand_intent]     Greeting / Question / Math / Farewell / General?
  ↓
[route_by_intent]  ──── CONDITIONAL EDGE (now 3-way)
  ↓         ↓         ↓
[greet]  [farewell] [help]     All record to message_history
  ↓         ↓         ↓
 END       END       END
```

---

## Multi-Turn Conversation Pattern

```
Turn 1:
  REPL builds: history = [{"role": "user", "content": "Hello!"}]
  invoke({..., "message_history": history})
  Response node appends: [{"role": "assistant", "content": "Namaste!..."}]
  result["message_history"] = [user_1, assistant_1]

Turn 2:
  REPL adds: history = [user_1, assistant_1, {"role": "user", "content": "bye"}]
  invoke({..., "message_history": history})
  farewell_response appends: [{"role": "assistant", "content": "Alvida!..."}]
  intent == "farewell" → REPL breaks the loop
```

---

## How to Run

```bash
# Activate venv first
.venv\Scripts\activate

# Interactive chat (what you want!)
python chat_loop.py

# With debug trace visible
python chat_loop.py --debug

# Still works as before
python run_hello_world.py

# Tests
pytest tests/ -v
```

**Special REPL commands:**
- `!history` — show full conversation so far
- `!debug`   — toggle graph trace on/off
- `!clear`   — reset conversation history

---

## Tests Added (Session 2)

| Test | What it checks |
|------|----------------|
| `test_farewell_english` | "bye" → intent == "farewell" |
| `test_farewell_hindi` | "alvida" → intent == "farewell" |
| `test_farewell_takes_highest_precedence` | "bye hello" → farewell wins |
| `test_exit_triggers_farewell` | "exit" → farewell |
| `test_response_appended_to_history` | history grows by 1 after each turn |
| `test_history_accumulates_across_turns` | 2 turns → 4 items in history |
| `test_farewell_shows_turn_count` | farewell response mentions turn count |

---

## Next Steps

### Tomorrow / This Week
- [ ] Run `python chat_loop.py` and have a real conversation with MAYA
- [ ] Try `python chat_loop.py --debug` to see the graph trace live
- [ ] Try `!history` command after a few turns
- [ ] LangGraph Academy modules (office time)

### When Ready - Option 2 (Ollama LLM)
- [ ] `pip install ollama`
- [ ] `ollama pull llama3.2:3b` (or phi3 for smaller)
- [ ] Replace `help_response` node body with `ollama.chat()` call
- [ ] MAYA becomes actually intelligent - same graph, smarter node
- [ ] Commit: `feat: integrate Ollama LLM for real AI responses`

### Week 2 (Next)
- [ ] Whisper STT - speak instead of type
- [ ] Piper TTS - MAYA speaks back
- [ ] Voice conversation loop

---

## Session Notes

> The chat loop is the most important milestone so far.
> MAYA can now hold a real conversation - it remembers what was said,
> exits gracefully, and the graph structure is clean enough to plug an
> LLM in with minimal changes.
>
> The Annotated reducer concept is fundamental to all LangGraph chat apps.
> Once you understand it here, you'll see it everywhere.
