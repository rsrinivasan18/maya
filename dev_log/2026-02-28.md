# MAYA Dev Log - 2026-02-28
## Session 4 - Week 3: Ollama LLM Integration

### Goals
- Replace rule-based `help_response` node with real Ollama LLM call
- MAYA becomes actually intelligent - answers STEM questions in Hinglish/English

### What We Built

#### 1. Ollama Integration (`src/maya/graph/hello_world_graph.py`)
- Installed `ollama==0.6.1` Python client
- Replaced `help_response` node body with `ollama.chat(model="llama3.2:3b", messages=...)`
- Passes full `message_history` to Ollama → context-aware multi-turn conversation
- Model: `llama3.2:3b` (Q4_K_M, ~2GB, runs fully offline on CPU)

#### 2. Bilingual System Prompt
- `_MAYA_BASE_PROMPT`: MAYA's core personality (warm, STEM, 10-year-old appropriate)
- `_LANGUAGE_INSTRUCTIONS`: Per-language reminder injected at call time
  - English → "respond in English only"
  - Hinglish → "respond in Hinglish naturally"
  - Hindi → "respond in Roman-script Hindi"
- `_build_system_prompt(language)` combines both per turn
- Rationale: llama3.2:3b is a 3B model - it needs explicit per-turn language reminders

#### 3. Edge Case Fix
- Tests invoke graph with empty `message_history`
- Added guard: if history is empty or last msg is not user → append `user_input` explicitly
- Ensures Ollama always has a user message to respond to

### Bugs Fixed
- `help_response` test failure: Ollama returned empty when `message_history=[]`
  Fix: Add `user_input` as fallback if message_history has no user message

### Test Results
- 30/30 tests passing (pytest)
- Ollama responses verified for English and Hinglish inputs

### Graph Structure
**UNCHANGED** - same nodes, same edges, same conditional routing.
Only `help_response` node internals changed. This is exactly the architecture principle.

### Python Environment
- Venv rebuilt with Python 3.13.2 (was 3.11) - all packages on cp313 wheels
- VSCode interpreter: set to `.venv\Scripts\python.exe` (Ctrl+Shift+P → Select Interpreter)

### Sample Outputs
**English** ("What is gravity?"):
> Gravity is like a magic string that pulls everything towards each other!
> Imagine you're playing cricket - when you throw the ball, it comes back down
> because of gravity's pull. Does that make sense?

**Hinglish** ("Kya hai photosynthesis?"):
> Srinika, photosynthesis yeh hai ki plants apni khadya banaate hain,
> khaad aur paani ke saath oxygen bhi utpann karti hain.
> Kya tumhara koi sawaal hai?

### Next Session (Week 3 continued or Week 4)
Options:
1. Add a `math_tutor` agent node - route math questions to a dedicated solver
2. Add SQLite memory - MAYA remembers daughter's name, past topics
3. Add LangSmith observability - trace every Ollama call

---

## Session 5 - Week 4: SQLite Memory

### Goals
- MAYA remembers Srinika across sessions
- "Welcome back! Last time you asked about photosynthesis."
- Persist turn history to SQLite, load it at conversation start

### What We Built

#### 1. `src/maya/agents/memory_store.py` (new file)
- `MemoryStore` class — SQLite at `~/.maya/memory.db`
- Tables:
  - `profile`: one row (user_name, session_count, total_turns)
  - `topics`: append-only turn log (session_id, message, intent, timestamp)
- Methods: `start_session()`, `get_profile()`, `get_recent_topics(limit)`, `log_turn()`
- DB path configurable via constructor → test isolation with `tmp_path`

#### 2. MayaState: 5 new NotRequired fields (`src/maya/models/state.py`)
- `user_name`, `session_count`, `recent_topics` — loaded by `load_memory`
- `session_id` — set by `chat_loop.py`, used by `save_memory` for tagging
- `memory_db_path` — test override (tests pass tmp_path, prod uses default)
- `NotRequired` = fully backward-compatible, existing 30 tests unchanged

#### 3. Graph topology change (`src/maya/graph/hello_world_graph.py`)
```
OLD: START → detect_language → understand_intent → [greet|farewell|help] → END
NEW: START → load_memory → detect_language → understand_intent → [greet|farewell|help] → save_memory → END
```
- `load_memory` (Node 0): reads profile + recent topics from SQLite, injects into state
- `save_memory` (final node): logs user_input + intent, increments total_turns

#### 4. greet_response updated
- session_count > 1 AND recent_topics → "Welcome back, Srinika! Last time: {last_topic}"
- session_count == 1 (first ever) → original introduction

#### 5. help_response updated (Ollama call)
- If recent_topics in state → prepends memory context to system prompt:
  `"Srinika has previously asked about: "gravity", "photosynthesis". Refer back if relevant."`

#### 6. `chat_loop.py` updated
- `MemoryStore().start_session()` called once at `run_chat()` startup
- Prints: `Memory: session #N | X total turns across all sessions`
- `session_id` passed into every `maya_graph.invoke()` call

### Test Results
- **33/33 tests passing** (pytest)
- 1 test fixed: `test_steps_show_correct_node_order` (index shift: load_memory is now step[0])
- 3 new tests added: `TestMemoryNodes`
  - `test_load_memory_returns_profile` — verifies user_name + session_count in state
  - `test_save_memory_logs_turn` — verifies user message logged to topics table
  - `test_fresh_install_defaults` — safe defaults on brand new DB

### Key Design Decision
Memory nodes instantiate `MemoryStore` fresh each call (no singleton).
This keeps the code simple, testable, and idiomatic. Tests inject `memory_db_path`
into state to use a `tmp_path` DB — zero coupling to the real DB.

### Next Session Options
1. Math Tutor agent — route math intent to a dedicated `math_tutor` node
2. LangSmith Observability — trace every Ollama call (free Developer tier)

---

## Session 5 Addendum — !reset-memory + Windows fix

### What We Added
- `MemoryStore.reset()` method: clears topics table + zeros session_count/total_turns in-place
- `chat_loop.py !reset-memory` command: calls `memory.reset()` then `start_session()`
- Also clears in-session message_history and turn_count

### Bug Fixed
- **PermissionError WinError 32** when `!reset-memory` tried to delete the DB file
- Root cause: SQLite holds a file lock on Windows even after `with conn:` exits
- Fix: use SQL `DELETE FROM` + `UPDATE` instead of `Path.unlink()` — no file deletion needed
- Committed: `f4075bc`

---

## Session 6 - Week 4: Math Tutor Agent

### Goals
- Dedicated math teaching agent (not generic LLM help)
- Step-by-step explanations, Indian everyday analogies, practice problems

### What We Built

#### 1. `_MATH_TUTOR_PROMPT` + `_build_math_prompt(language)` (`hello_world_graph.py`)
- Separate system prompt for math: "solve first, explain each step, use analogies"
- Analogies: rupees, cricket scores, chai cups, apples
- Ends every response with a practice problem
- Per-language instructions same as base prompt (English/Hindi/Hinglish)

#### 2. `math_tutor_response` node (new, `hello_world_graph.py`)
- Same Ollama call pattern as `help_response` — only system prompt differs
- This IS the multi-agent principle: same model, different instructions = different agent
- Graceful fallback if Ollama unreachable

#### 3. Router updated: 3-way → 4-way (`route_by_intent`)
- greeting → greet_response
- farewell → farewell_response
- **math → math_tutor_response** (NEW)
- everything else → help_response

#### 4. Graph topology
```
START → load_memory → detect_language → understand_intent
      → [greet | farewell | math_tutor | help] → save_memory → END
```

#### 5. Test fix: `test_math_routes_to_help_response` → `test_math_routes_to_math_tutor_response`
- Old test was wrong after Session 6 routing change
- 4 new tests in `TestMathTutorAgent`

### Test Results
- **37/37 tests passing**
- 1 test renamed (routing changed)
- 4 new: `TestMathTutorAgent`
  - `test_math_routes_to_math_tutor`
  - `test_math_tutor_not_in_help_response`
  - `test_math_tutor_produces_response`
  - `test_non_math_still_goes_to_help`

### Next Session Options
1. LangSmith Observability — trace every Ollama call (free Developer tier)
2. Animated face display — Pygame face showing emotions (Week 6)

---

## Session 6 Addendum — Farewell not saved to topics

### Bug
After saying "bye", the next session's welcome-back message read:
> "Last time you asked about: 'bye'."

Root cause: `save_memory` logged ALL turns including farewell intent.

### Fix (`src/maya/graph/hello_world_graph.py`)
Added early-return in `save_memory` when `intent == "farewell"`:
```python
if intent == "farewell":
    return {"steps": current_steps + ["[save_memory] → skipped (farewell)"]}
```
Farewell is a command, not a topic — should never appear in recent topics.

### New Test (`tests/test_hello_world.py`)
`test_farewell_not_saved_to_topics` — invokes graph with "bye", confirms topics table stays empty.

### Test Results
- **38/38 tests passing**

### Next Session Options
1. LangSmith Observability — trace every Ollama call (free Developer tier)
2. Animated face display — Pygame face showing emotions (Week 6)
