# MAYA - Multi-Agent hYbrid Assistant
# Python dependencies
# Updated: 2026-02-27

# ─── Core: LangGraph & LangChain ───────────────────────────────────────────────
langgraph>=0.2.0
langchain>=0.3.0
langchain-community>=0.3.0
langsmith>=0.1.0               # Observability — traces every LangGraph run to dashboard

# ─── Configuration ─────────────────────────────────────────────────────────────
python-dotenv>=1.0.0

# ─── Terminal UI (pretty output while learning) ────────────────────────────────
rich>=13.0.0

# ─── Testing ───────────────────────────────────────────────────────────────────
pytest>=8.0.0

# ─── Week 3: Local LLM via Ollama ──────────────────────────────────────────────
ollama>=0.6.0                  # Ollama Python client (llama3.2:3b runs locally)
# langchain-anthropic>=0.3.0     # Claude API (future)
# langchain-ollama>=0.2.0        # LangChain Ollama wrapper (future)

# ─── Week 3: Sarvam AI (Hindi/English bilingual model) ─────────────────────────
# sarvam-python                  # Check PyPI for official package name

# ─── Week 2: Speech-to-Text ────────────────────────────────────────────────────
faster-whisper>=1.0.0          # STT - 4x faster than openai-whisper, int8 on CPU
sounddevice>=0.4.6             # Microphone recording (bundles PortAudio on Windows)
numpy>=1.24.0                  # Audio array handling

# ─── Week 2: Text-to-Speech ────────────────────────────────────────────────────
piper-tts>=1.4.0               # TTS - neural offline voices via ONNX
# huggingface-hub already installed as faster-whisper dependency (voice download)

# ─── Phase 2: Web Backend (uncomment when ready) ───────────────────────────────
# fastapi>=0.115.0
# uvicorn>=0.30.0
